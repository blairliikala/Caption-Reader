<!doctype html>
<html lang="en-GB">
<head>
  <meta charset="utf-8">
  <title>Caption Reader Web Component - HLS.js</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="color-scheme" content="dark light">
  <link href="demo.css" rel="stylesheet" type="text/css">
  <script type="module" src="/captions-viewer.js"></script>
  <script defer src="/_vercel/insights/script.js"></script>

  <style>
    /* Hides the component until it has loaded */
    captions-viewer:not(:defined) {
      visibility: hidden
    }
    captions-viewer {
      margin: 1em 0;
      border: 3px solid hsla(200, 20%, 50%, .5);
      border-radius: 5px;
      font-family: arial;
      display: block;
      background: rgba(0,0,0,.2);
    }
  </style>
</head>
<body>

  <main class="container">

    <section class="info">
      <p>Example showing an HLS feed, using hls.js, with embedded captions that update as chunks are added.</p>
      <p>While this works, it is currently less than ideal. More improvement to come in the future.</p>
    </section>

    <video controls width="100%" playsinline></video>

    <captions-viewer
      height="25vh"
      theme="dark"
      disable="chapters"
      debounce="1000"
    >
    </captions-viewer>

    <p>Find it on <a href="https://github.com/blairliikala/Caption-Reader">Github</a>.</p>
  </main>

  <script src="https://cdn.jsdelivr.net/npm/hls.js@latest"></script>
  <script type="module">
    const component = document.querySelector('captions-viewer');
    const player = document.querySelector('video');

    // function to check for when textTrack is ready.
    const trackReady = (video) => {
      console.time('trackReady')
      let count = 0;
      return new Promise((resolve, rejected) => {
        const interval = setInterval(() => {
          count += 1;
          if (count > 1000) {
            clearInterval(interval);
            console.timeEnd('trackReady')
            rejected('No tracks found in time.');
          }
          const textTracks = Array.from(video.textTracks);
          if (textTracks.length > 0) {
            const subtitles = textTracks.find(track => track.kind === 'captions' || track.kind === 'subtitles');
            if (subtitles) {
              clearInterval(interval);
              console.timeEnd('trackReady')
              resolve();
            }
          }
        }, 2);
      });
    }

    const cuesReady = (track) => {
      console.time('cuesReady')
      let count = 0;
      return new Promise((resolve, rejected) => {
        const interval = setInterval(() => {
          count += 1;
          if (count > 1000) {
            clearInterval(interval);
            console.timeEnd('cuesReady')
            rejected('No cues found in time.');
          }
          if (track.cues && track.cues.length > 0) {
            clearInterval(interval);
            console.timeEnd('cuesReady')
            resolve();
          }
        }, 2);
      });
    }

    async function setCaptionReader(player) {
      await trackReady(player).catch(error => {
        console.error(error);
      });
      const tracks = player.textTracks;
      const track = Array.from(tracks).find(track => track.kind === 'subtitles');
      if (!track) {
        console.error('No subtitle track found.', {tracks});
        return;
      }
      track.mode = 'hidden';
      await cuesReady(track).catch(error => {
        console.error(error);
      });
      component.textTrack = track;
      track.addEventListener('cuechange', (e) => {
        component.updateCues(e.target);
      });
    }

    // const videoSrc = 'https://test-streams.mux.dev/x36xhzz/x36xhzz.m3u8'; // Bunny.
    // const videoSrc = 'http://stream.mux.com/qP5Eb2cj7MrNnoxBGz012pbZkMHqpIcrKMzd7ykGr01gM.m3u8' // Tears
    // const videoSrc = 'https://playertest.longtailvideo.com/adaptive/captions/playlist.m3u8'; // CNN
    const videoSrc = 'https://devstreaming-cdn.apple.com/videos/streaming/examples/bipbop_adv_example_hevc/master.m3u8'; // beep boop.
    // const videoSrc = 'https://stream.mux.com/qP5Eb2cj7MrNnoxBGz012pbZkMHqpIcrKMzd7ykGr01gM.m3u8';
    if (Hls.isSupported()) {
      console.log('HLS is supported')
      const hls = new Hls();
      hls.loadSource(videoSrc);
      hls.attachMedia(player);
      hls.on(Hls.Events.MANIFEST_PARSED, (e) => {
        player.addEventListener('loadedmetadata', async (e) => {
          setCaptionReader(player);
        })
      });
    } else if (player.canPlayType('application/vnd.apple.mpegurl')) {
      console.log('HLS.js is not supported, HLS is native.');
      player.src = videoSrc;
      player.addEventListener('play', (e) => {
        setCaptionReader(player);
      });
    } else {
      console.warn('There be issues.');
    }

    // Using intervals to check for caption updates instead of play,
    // so that 1 second cues show quicker.
    let pingInterval;
    const update = 100;
    player.addEventListener('play', () => {
      component.playhead = player.currentTime;
      pingInterval = setInterval(() => {
        component.playhead = player.currentTime;
      })
    }, update);
    player.addEventListener('pause', () => {
      clearInterval(pingInterval);
    })

    // On click, Seek's player to caption location.
    component.addEventListener('seek', e => {
      player.currentTime = e.detail.value;
    });

    // (optional) Scroll to the cue when user skips in the player timeline.
    player.onseeking = () => {
      component.debounceScrolling = false;
    };

    component.addEventListener('all', (e) => {
      console.log(e.detail);
    })

  </script>

</body>
</html>
